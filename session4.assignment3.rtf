{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Input :word-count.txt on hdfs \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\fs22 \cf2 \cb3 \CocoaLigature0 It just came to me so strongly and vividly that I knew I had to write it, he told Rolling Stone\
\
\
PIG script for word count:\
lines = LOAD '/user/acadgild/hadoop/word-count.txt' AS (line:chararray);\
words = FOREACH lines GENERATE FLATTEN(TOKENIZE(line)) as word;\
words_grouped = GROUP words by word;\
wordcount = FOREACH words_grouped GENERATE group, COUNT(words);\
dump wordcount;\
\
execution command:\
\
Chaitanyas-MacBook-Pro:~ Disha$ pig wordcountscript.pig\
\
\
output:\
(I,2)\
(It,1)\
(he,1)\
(it,1)\
(me,1)\
(so,1)\
(to,2)\
(and,1)\
(had,1)\
(came,1)\
(just,1)\
(knew,1)\
(that,1)\
(told,1)\
(Stone,1)\
(write,1)\
(Rolling,1)\
(vividly,1)\
(strongly,1)\
\
\
execution steps:\
\
Chaitanyas-MacBook-Pro:~ Disha$ pig wordcountscript.pig \
17/09/05 18:40:37 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\
17/09/05 18:40:37 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE\
17/09/05 18:40:37 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType\
2017-09-05 18:40:37,456 [main] INFO  org.apache.pig.Main - Apache Pig version 0.16.0 (r1746530) compiled Jun 01 2016, 23:10:49\
2017-09-05 18:40:37,457 [main] INFO  org.apache.pig.Main - Logging error messages to: /Users/Disha/pig_1504617037454.log\
2017-09-05 18:40:38,185 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
2017-09-05 18:40:38,787 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /Users/Disha/.pigbootup not found\
2017-09-05 18:40:38,911 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\
2017-09-05 18:40:38,911 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\
2017-09-05 18:40:38,912 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://localhost:9000\
2017-09-05 18:40:39,612 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-wordcountscript.pig-ad8954d9-daf3-42e0-841b-c2823f2189de\
2017-09-05 18:40:39,612 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\
2017-09-05 18:40:40,414 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\
2017-09-05 18:40:40,591 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\
2017-09-05 18:40:40,835 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY\
2017-09-05 18:40:40,901 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\
2017-09-05 18:40:40,907 [main] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\
2017-09-05 18:40:40,970 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - \{RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]\}\
2017-09-05 18:40:41,131 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\
2017-09-05 18:40:41,155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\
2017-09-05 18:40:41,207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 1\
2017-09-05 18:40:41,207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 1\
2017-09-05 18:40:41,255 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\
2017-09-05 18:40:41,282 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\
2017-09-05 18:40:41,285 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\
2017-09-05 18:40:41,732 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\
2017-09-05 18:40:41,739 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\
2017-09-05 18:40:41,739 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\
2017-09-05 18:40:41,739 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\
2017-09-05 18:40:41,743 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\
2017-09-05 18:40:41,744 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\
2017-09-05 18:40:41,778 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=96\
2017-09-05 18:40:41,778 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\
2017-09-05 18:40:41,779 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\
2017-09-05 18:40:41,779 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\
2017-09-05 18:40:41,795 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\
2017-09-05 18:40:42,303 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/Cellar/pig/0.16.0/libexec/pig-0.16.0-core-h2.jar to DistributedCache through /tmp/temp-552041297/tmp-1747820864/pig-0.16.0-core-h2.jar\
2017-09-05 18:40:42,358 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/Cellar/pig/0.16.0/libexec/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-552041297/tmp-599603225/automaton-1.11-8.jar\
2017-09-05 18:40:42,432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/Cellar/pig/0.16.0/libexec/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-552041297/tmp-1965225173/antlr-runtime-3.4.jar\
2017-09-05 18:40:42,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/Cellar/pig/0.16.0/libexec/lib/joda-time-2.9.3.jar to DistributedCache through /tmp/temp-552041297/tmp-1448984597/joda-time-2.9.3.jar\
2017-09-05 18:40:42,501 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\
2017-09-05 18:40:42,507 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\
2017-09-05 18:40:42,507 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\
2017-09-05 18:40:42,508 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\
2017-09-05 18:40:42,606 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\
2017-09-05 18:40:42,607 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\
2017-09-05 18:40:42,618 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:42,633 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\
2017-09-05 18:40:43,144 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\
2017-09-05 18:40:43,209 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\
2017-09-05 18:40:43,216 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\
2017-09-05 18:40:43,216 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\
2017-09-05 18:40:43,247 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\
2017-09-05 18:40:43,329 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\
2017-09-05 18:40:43,461 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1046836482_0001\
2017-09-05 18:40:44,007 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043559/pig-0.16.0-core-h2.jar <- /Users/Disha/pig-0.16.0-core-h2.jar\
2017-09-05 18:40:44,255 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized hdfs://localhost:9000/tmp/temp-552041297/tmp-1747820864/pig-0.16.0-core-h2.jar as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043559/pig-0.16.0-core-h2.jar\
2017-09-05 18:40:44,255 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043560/automaton-1.11-8.jar <- /Users/Disha/automaton-1.11-8.jar\
2017-09-05 18:40:44,262 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized hdfs://localhost:9000/tmp/temp-552041297/tmp-599603225/automaton-1.11-8.jar as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043560/automaton-1.11-8.jar\
2017-09-05 18:40:44,262 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043561/antlr-runtime-3.4.jar <- /Users/Disha/antlr-runtime-3.4.jar\
2017-09-05 18:40:44,268 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized hdfs://localhost:9000/tmp/temp-552041297/tmp-1965225173/antlr-runtime-3.4.jar as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043561/antlr-runtime-3.4.jar\
2017-09-05 18:40:44,268 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043562/joda-time-2.9.3.jar <- /Users/Disha/joda-time-2.9.3.jar\
2017-09-05 18:40:44,274 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized hdfs://localhost:9000/tmp/temp-552041297/tmp-1448984597/joda-time-2.9.3.jar as file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043562/joda-time-2.9.3.jar\
2017-09-05 18:40:44,398 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043559/pig-0.16.0-core-h2.jar\
2017-09-05 18:40:44,398 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043560/automaton-1.11-8.jar\
2017-09-05 18:40:44,398 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043561/antlr-runtime-3.4.jar\
2017-09-05 18:40:44,398 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/usr/local/Cellar/hadoop/hdfs/tmp/mapred/local/1504617043562/joda-time-2.9.3.jar\
2017-09-05 18:40:44,403 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\
2017-09-05 18:40:44,404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1046836482_0001\
2017-09-05 18:40:44,404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases lines,wordcount,words,words_grouped\
2017-09-05 18:40:44,404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: lines[1,8],words[-1,-1],wordcount[4,12],words_grouped[3,16] C: wordcount[4,12],words_grouped[3,16] R: wordcount[4,12]\
2017-09-05 18:40:44,406 [Thread-29] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\
2017-09-05 18:40:44,411 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\
2017-09-05 18:40:44,412 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1046836482_0001]\
2017-09-05 18:40:44,445 [Thread-29] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\
2017-09-05 18:40:44,445 [Thread-29] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\
2017-09-05 18:40:44,445 [Thread-29] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\
2017-09-05 18:40:44,450 [Thread-29] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\
2017-09-05 18:40:44,450 [Thread-29] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2017-09-05 18:40:44,450 [Thread-29] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\
2017-09-05 18:40:44,720 [Thread-29] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\
2017-09-05 18:40:44,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1046836482_0001_m_000000_0\
2017-09-05 18:40:44,837 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\
2017-09-05 18:40:44,837 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2017-09-05 18:40:44,853 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.\
2017-09-05 18:40:44,853 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null\
2017-09-05 18:40:44,862 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\
Total Length = 96\
Input split[0]:\
   Length = 96\
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\
   Locations:\
\
-----------------------\
\
2017-09-05 18:40:44,871 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\
2017-09-05 18:40:44,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed hdfs://localhost:9000/user/acadgild/hadoop/word-count.txt:0+96\
2017-09-05 18:40:44,906 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\
2017-09-05 18:40:44,906 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\
2017-09-05 18:40:44,906 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\
2017-09-05 18:40:44,906 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\
2017-09-05 18:40:44,906 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\
2017-09-05 18:40:44,913 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
2017-09-05 18:40:44,923 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\
2017-09-05 18:40:44,967 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\
2017-09-05 18:40:44,982 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: lines[1,8],words[-1,-1],wordcount[4,12],words_grouped[3,16] C: wordcount[4,12],words_grouped[3,16] R: wordcount[4,12]\
2017-09-05 18:40:45,118 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \
2017-09-05 18:40:45,118 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\
2017-09-05 18:40:45,118 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\
2017-09-05 18:40:45,118 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 242; bufvoid = 104857600\
2017-09-05 18:40:45,118 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600\
2017-09-05 18:40:45,194 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: lines[1,8],words[-1,-1],wordcount[4,12],words_grouped[3,16] C: wordcount[4,12],words_grouped[3,16] R: wordcount[4,12]\
2017-09-05 18:40:45,207 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\
2017-09-05 18:40:45,213 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1046836482_0001_m_000000_0 is done. And is in the process of committing\
2017-09-05 18:40:45,239 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\
2017-09-05 18:40:45,239 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1046836482_0001_m_000000_0' done.\
2017-09-05 18:40:45,239 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1046836482_0001_m_000000_0\
2017-09-05 18:40:45,241 [Thread-29] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\
2017-09-05 18:40:45,244 [Thread-29] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\
2017-09-05 18:40:45,245 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1046836482_0001_r_000000_0\
2017-09-05 18:40:45,276 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\
2017-09-05 18:40:45,276 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2017-09-05 18:40:45,281 [pool-7-thread-1] INFO  org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.\
2017-09-05 18:40:45,282 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null\
2017-09-05 18:40:45,287 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2f3a8a22\
2017-09-05 18:40:45,327 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\
2017-09-05 18:40:45,331 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1046836482_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\
2017-09-05 18:40:45,392 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1046836482_0001_m_000000_0 decomp: 265 len: 269 to MEMORY\
2017-09-05 18:40:45,400 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 265 bytes from map-output for attempt_local1046836482_0001_m_000000_0\
2017-09-05 18:40:45,402 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 265, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->265\
2017-09-05 18:40:45,405 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\
2017-09-05 18:40:45,406 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\
2017-09-05 18:40:45,406 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\
2017-09-05 18:40:45,415 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\
2017-09-05 18:40:45,416 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\
2017-09-05 18:40:45,416 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1046836482_0001]\
2017-09-05 18:40:45,416 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 259 bytes\
2017-09-05 18:40:45,418 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 265 bytes to disk to satisfy reduce memory limit\
2017-09-05 18:40:45,419 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 269 bytes from disk\
2017-09-05 18:40:45,420 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\
2017-09-05 18:40:45,420 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\
2017-09-05 18:40:45,455 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 259 bytes\
2017-09-05 18:40:45,457 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\
2017-09-05 18:40:45,465 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\
2017-09-05 18:40:45,465 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
2017-09-05 18:40:45,477 [pool-7-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\
2017-09-05 18:40:45,477 [pool-7-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\
2017-09-05 18:40:45,478 [pool-7-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\
2017-09-05 18:40:45,488 [pool-7-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: lines[1,8],words[-1,-1],wordcount[4,12],words_grouped[3,16] C: wordcount[4,12],words_grouped[3,16] R: wordcount[4,12]\
2017-09-05 18:40:45,721 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1046836482_0001_r_000000_0 is done. And is in the process of committing\
2017-09-05 18:40:45,782 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\
2017-09-05 18:40:45,782 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1046836482_0001_r_000000_0 is allowed to commit now\
2017-09-05 18:40:45,894 [pool-7-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1046836482_0001_r_000000_0' to hdfs://localhost:9000/tmp/temp-552041297/tmp1063609702/_temporary/0/task_local1046836482_0001_r_000000\
2017-09-05 18:40:45,895 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\
2017-09-05 18:40:45,895 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1046836482_0001_r_000000_0' done.\
2017-09-05 18:40:45,895 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1046836482_0001_r_000000_0\
2017-09-05 18:40:45,896 [Thread-29] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\
2017-09-05 18:40:45,920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1046836482_0001]\
2017-09-05 18:40:49,448 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:49,456 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:49,457 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\
2017-09-05 18:40:49,459 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:49,496 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\
2017-09-05 18:40:49,499 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \
\
HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features\
2.8.1	0.16.0	Disha	2017-09-05 18:40:41	2017-09-05 18:40:49	GROUP_BY\
\
Success!\
\
Job Stats (time in seconds):\
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs\
job_local1046836482_0001	1	1	n/a	n/a	n/a	n/a	n/a	n/a	n/a	n/a	lines,wordcount,words,words_grouped	GROUP_BY,COMBINER	hdfs://localhost:9000/tmp/temp-552041297/tmp1063609702,\
\
Input(s):\
Successfully read 1 records (10756606 bytes) from: "/user/acadgild/hadoop/word-count.txt"\
\
Output(s):\
Successfully stored 19 records (10756639 bytes) in: "hdfs://localhost:9000/tmp/temp-552041297/tmp1063609702"\
\
Counters:\
Total records written : 19\
Total bytes written : 10756639\
Spillable Memory Manager spill count : 0\
Total bags proactively spilled: 0\
Total records proactively spilled: 0\
\
Job DAG:\
job_local1046836482_0001\
\
\
2017-09-05 18:40:49,501 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:49,504 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:49,506 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\
2017-09-05 18:40:49,517 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\
2017-09-05 18:40:49,521 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\
2017-09-05 18:40:49,522 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\
2017-09-05 18:40:49,529 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\
2017-09-05 18:40:49,530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\
(I,2)\
(It,1)\
(he,1)\
(it,1)\
(me,1)\
(so,1)\
(to,2)\
(and,1)\
(had,1)\
(came,1)\
(just,1)\
(knew,1)\
(that,1)\
(told,1)\
(Stone,1)\
(write,1)\
(Rolling,1)\
(vividly,1)\
(strongly,1)\
\
\
\
\
}